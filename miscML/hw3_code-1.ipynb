{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kLbL-LlnOAgm"
   },
   "source": [
    "# Homework 3 Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0aSWrpaElDM0"
   },
   "outputs": [],
   "source": [
    "# Add import statements here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "\n",
    "clevelandTestData = pd.read_csv(\"cleveland_test.csv\")\n",
    "clevelandTrainData = pd.read_csv(\"cleveland_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TDvZ5xhsl9XM"
   },
   "outputs": [],
   "source": [
    "# To access files in your Google Drive, run this block and follow the instructions\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hi_dRrJDmtiI"
   },
   "outputs": [],
   "source": [
    "# To test if the above block worked, run this block\n",
    "!ls '/content/gdrive/My Drive/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i1rrY8fIxz7h"
   },
   "source": [
    " ## Find test error\n",
    "\n",
    "The `find_test_error` function computes the test error of a linear classifier $w$. \n",
    "\n",
    "The hypothesis is assumed to be of the form $sign([1, x(N,:)] \\cdot w)$.\n",
    "\n",
    "Inputs:\n",
    "* `w` is the weight vector\n",
    "* `X` is the data matrix (without an initial column of 1's)\n",
    "* `y` are the data labels (plus or minus 1)\n",
    "\n",
    "Outputs:\n",
    "* `test_error` is the binary error of $w$ on the data set $(X, y)$ error; this should be between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0BCKbvjMlHtE"
   },
   "outputs": [],
   "source": [
    "def find_test_error(w, X, y):\n",
    "    x = np.ones((len(X), len(X[0]) + 1))\n",
    "    x[: , :-1] = X\n",
    "    X = x\n",
    "    test_error = 0\n",
    "    tempY = np.sign(np.matmul(X, np.transpose(w)))\n",
    "#    tempY = np.sign(np.matmul(np.transpose(w),X))\n",
    "    for i in range(len(y)):\n",
    "        if tempY[i]!= y[i]:\n",
    "            test_error = test_error+1\n",
    "    return test_error/len(y)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUF6Mr1V0S5T"
   },
   "source": [
    " ## Logistic Regression\n",
    "\n",
    "The `logistic_reg`  learn a logistic regression model using gradient descent.\n",
    "\n",
    "Inputs:\n",
    "* `X` is the data matrix (without an initial column of 1's)\n",
    "* `y` are the data labels (plus or minus 1)\n",
    "* `w_init` is the initial value of the w vector ($d+1$ dimensional)\n",
    "* `max_its` is the maximum number of iterations to run for\n",
    "* `eta` is the learning rate\n",
    "\n",
    "Outputs:\n",
    "* t is the number of iterations gradient descent ran for\n",
    "* w is the learned weight vector\n",
    "* e_in is the in-sample (cross-entropy) error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dTcJkPE6lHvg"
   },
   "outputs": [],
   "source": [
    "def logistic_reg(X, y, w_init, max_its, eta):\n",
    "\n",
    "  # Your code here, assign the proper values to t, w, and e_in:\n",
    "# Your code here.\n",
    "#w(t+1) = w(t)+eta*V\n",
    "    x = np.ones((len(X), len(X[0]) + 1))\n",
    "    x[: , :-1] = X\n",
    "    X = x\n",
    "    w = w_init\n",
    "    e_in = 0\n",
    "    t = 0\n",
    "    for i in range(max_its):\n",
    "        t = t+1\n",
    "        gradient = np.zeros(len(w))\n",
    "        for i in range(len(X)):\n",
    "            #print(y[i]*X[i])\n",
    "            #print(math.exp(y[i]*np.transpose(w)*X[i]))\n",
    "            #print(y[i]*np.matmul(np.transpose(w),X[i]))\n",
    "            #print((1+math.exp(y[i]*np.transpose(w)*X[i])))\n",
    "            gradient = gradient + (y[i]* X[i])/(1+math.exp(y[i]*np.matmul(np.transpose(w),X[i])))\n",
    "        if np.linalg.norm(gradient) <= .001:\n",
    "            break\n",
    "        gradientExpression = eta*gradient*(1/len(X))\n",
    "        w = w + gradientExpression\n",
    "    for i in range(len(X)):\n",
    "        e_in = e_in+np.log(1+math.exp(-y[i]*np.matmul(np.transpose(w),X[i])))\n",
    "    e_in = e_in/len(X)\n",
    "      \n",
    "    return t, w, e_in\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q7d-boqb0y_H"
   },
   "source": [
    "## Run and Plot\n",
    "\n",
    "Run your code and plot figures below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FWHPRXv4lHx6"
   },
   "outputs": [],
   "source": [
    "# Other code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z3mrOrbBLQuC",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -1. -1. -1.  1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.  1.  1.\n",
      " -1. -1.  1.  1. -1.  1. -1.  1.  1. -1. -1. -1. -1. -1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1.  1.  1.  1.\n",
      "  1.  1. -1. -1. -1.  1. -1.  1.  1. -1. -1. -1.  1. -1.  1. -1.  1. -1.\n",
      " -1. -1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1. -1.  1. -1.  1.  1.\n",
      "  1.  1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      " -1.  1. -1.  1. -1.  1. -1. -1. -1. -1. -1.  1.  1.  1. -1.  1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1.  1.  1.  1.  1. -1.  1. -1. -1. -1.  1.  1. -1.\n",
      " -1.  1.  1. -1.  1.  1.  1.  1.]\n",
      "[-1.  1. -1.  1.  1.  1. -1. -1. -1.  1. -1. -1. -1.  1.  1. -1.  1. -1.\n",
      " -1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1.\n",
      " -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1. -1.\n",
      "  1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1. -1. -1. -1. -1.  1.  1. -1.\n",
      " -1.  1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1.\n",
      " -1. -1.  1. -1. -1. -1.  1. -1.  1.  1. -1. -1. -1.  1.  1.  1.  1.  1.\n",
      " -1. -1. -1.  1. -1. -1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1. -1.\n",
      "  1.  1. -1.  1. -1.  1. -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  1.]\n",
      "10^4 its:\n",
      "cross entropy train: 0.5847145522443017\n",
      "cross entropy test: 0.5574582141185064\n",
      "10000\n",
      "clock time diff: 14.094101905822754\n",
      "done\n",
      "binary test: 0.31724137931034485\n",
      "binary train: 0.3092105263157895\n",
      "10^5 its:\n",
      "cross entropy train: 0.49370175927710547\n",
      "cross entropy test: 0.4480702034122813\n",
      "100000\n",
      "clock time diff: 142.81957817077637\n",
      "done\n",
      "binary test: 0.20689655172413793\n",
      "binary train: 0.2236842105263158\n",
      "10^6 its:\n",
      "cross entropy train: 0.43535260915252544\n",
      "cross entropy test: 0.34610891492569845\n",
      "1000000\n",
      "clock time diff: 1392.041049003601\n",
      "done\n",
      "binary test: 0.1310344827586207\n",
      "binary train: 0.1513157894736842\n"
     ]
    }
   ],
   "source": [
    "numpyTrain = clevelandTrainData.to_numpy()\n",
    "yTrain = numpyTrain[:,len(numpyTrain[0])-1]\n",
    "\n",
    "for i in range(len(yTrain)):\n",
    "    if yTrain[i] == 0:\n",
    "        yTrain[i]= -1\n",
    "print(yTrain)\n",
    "xTrain = np.delete(numpyTrain, len(numpyTrain[0])-1, axis=1)\n",
    "\n",
    "numpyTest = clevelandTestData.to_numpy()\n",
    "yTest = numpyTest[:,len(numpyTest[0])-1]\n",
    "for i in range(len(yTest)):\n",
    "    if yTest[i] == 0:\n",
    "        yTest[i]= -1\n",
    "print(yTest)\n",
    "xTest = np.delete(numpyTest, len(numpyTest[0])-1, axis=1)\n",
    "\n",
    "def find_cross_entropy(X, y, w):\n",
    "    x = np.ones((len(X), len(X[0]) + 1))\n",
    "    x[: , :-1] = X\n",
    "    X = x\n",
    "    e_in = 0\n",
    "    for i in range(len(X)):\n",
    "        e_in = e_in+np.log(1+math.exp(-y[i]*np.matmul(np.transpose(w),X[i])))\n",
    "    e_in = e_in/len(X)\n",
    "    return e_in\n",
    "\n",
    "#constraints for logistical \n",
    "eta = .00001\n",
    "wInit = np.zeros(len(numpyTrain[0]))\n",
    "maxIts = 10000\n",
    "firstItTime = time.time()\n",
    "t, w, e_in = logistic_reg(xTrain, yTrain, wInit, maxIts, eta)\n",
    "resTime = time.time()\n",
    "print(\"10^4 its:\")\n",
    "print(\"cross entropy train: \"+str(e_in))\n",
    "print(\"cross entropy test: \" + str(find_cross_entropy(xTest, yTest, w)))\n",
    "#print(w)\n",
    "print(t)\n",
    "print(\"clock time diff: \"+ str(resTime-firstItTime))\n",
    "print(\"done\")\n",
    "test_err = find_test_error(w, xTest, yTest)\n",
    "print(\"binary test: \" + str(test_err))\n",
    "train_err = find_test_error(w, xTrain, yTrain)\n",
    "print(\"binary train: \" + str(train_err))\n",
    "\n",
    "maxIts = 100000\n",
    "firstItTime = time.time()\n",
    "t, w, e_in = logistic_reg(xTrain, yTrain, wInit, maxIts, eta)\n",
    "resTime = time.time()\n",
    "print(\"10^5 its:\")\n",
    "print(\"cross entropy train: \"+ str(e_in))\n",
    "print(\"cross entropy test: \" + str(find_cross_entropy(xTest, yTest, w)))\n",
    "#print(w)\n",
    "print(t)\n",
    "print(\"clock time diff: \"+ str(resTime-firstItTime))\n",
    "print(\"done\")\n",
    "test_err = find_test_error(w, xTest, yTest)\n",
    "print(\"binary test: \" + str(test_err))\n",
    "train_err = find_test_error(w, xTrain, yTrain)\n",
    "print(\"binary train: \" + str(train_err))\n",
    "\n",
    "maxIts = 1000000\n",
    "firstItTime = time.time()\n",
    "t, w, e_in = logistic_reg(xTrain, yTrain, wInit, maxIts, eta)\n",
    "resTime = time.time()\n",
    "print(\"10^6 its:\")\n",
    "print(\"cross entropy train: \"+str(e_in))\n",
    "print(\"cross entropy test: \" + str(find_cross_entropy(xTest, yTest, w)))\n",
    "#print(w)\n",
    "print(t)\n",
    "print(\"clock time diff: \"+ str(resTime-firstItTime))\n",
    "print(\"done\")\n",
    "test_err = find_test_error(w, xTest, yTest)\n",
    "print(\"binary test: \" + str(test_err))\n",
    "train_err = find_test_error(w, xTrain, yTrain)\n",
    "print(\"binary train: \" + str(train_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPIe/HzMLpv7tQhj5BwpQ/r",
   "collapsed_sections": [],
   "name": "hw3_code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
